{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "spacytokenize_PartAWorking_gpu.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qHZm9Eg-rSy",
        "colab_type": "code",
        "outputId": "43f8fb14-5428-4ec5-96e7-cc0e7bb7236e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive/My Drive/NLP_P4"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "/gdrive/My Drive/NLP_P4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AG8181AQRH2a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "d7c25e69-c443-4c2c-890b-db1612d73b57"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dev.csv\t\t\t\t      spacy_word2vec32.model\n",
            "gpu_dev.csv\t\t\t      test.csv\n",
            "gpu_test.csv\t\t\t      train.csv\n",
            "gpu_train.csv\t\t\t      train.ipynb\n",
            "nltk_word2vec32.model\t\t      train.py\n",
            "P4.pdf\t\t\t\t      Untitled.ipynb\n",
            "Part-A_rnnlm-baseline-e10-a67.csv     word2vec128.model\n",
            "Pipfile\t\t\t\t      word2vec16.model\n",
            "Pipfile.lock\t\t\t      word2vec24.model\n",
            "README.md\t\t\t      word2vec32.model\n",
            "spacytokenize_PartAWorking_gpu.ipynb  word2vec64.model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suam4b4K5FEF",
        "colab_type": "code",
        "outputId": "13cdbeab-ceee-4c41-df8b-8247574d756f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import os\n",
        "import math\n",
        "import time\n",
        "import nltk\n",
        "import random\n",
        "import spacy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn import init\n",
        "from nltk.tokenize import word_tokenize\n",
        "from gensim.models import Word2Vec\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "# from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "nltk.download('punkt')\n",
        "get_pos = spacy.load(\"en_core_web_sm\")\n",
        "# analyser = SentimentIntensityAnalyzer()\n",
        "train_data = pd.read_csv('./gpu_train.csv', encoding='latin-1')\n",
        "dev_data = pd.read_csv('./gpu_dev.csv', encoding='latin-1')\n",
        "test_data = pd.read_csv('./gpu_test.csv', encoding='latin-1')\n",
        "data = [train_data, dev_data, test_data]\n",
        "\n",
        "PATH = './'\n",
        "\n",
        "EMBED_DIM = 32\n",
        "HIDDEN_DIM = 16\n",
        "LAYERS = 1\n",
        "EPOCHS = 1000\n",
        "LR = 3e-4\n",
        "DEVICE = torch.device(\"cuda:0\")"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyQEYCMM5FEX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def sentiment_analyzer_scores(sentence):\n",
        "#     return analyser.polarity_scores(sentence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_GVxlfx5FEx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list_of_sentences = []\n",
        "def tag_pos(data):\n",
        "    all_pos = []\n",
        "    pos_counts = Counter()\n",
        "\n",
        "    for df in data:\n",
        "        df_pos = []\n",
        "        for row in df.iterrows():\n",
        "            row_pos = []\n",
        "            for i in range(1, 7):\n",
        "                parts_of_speech = get_pos(row[1][i])\n",
        "                list_of_sentences.append([pos.text for pos in parts_of_speech])\n",
        "                sentence_pos = [pos.pos_ for pos in parts_of_speech]\n",
        "#                 sentence_pos = [row[1][i], sentence_pos] #temporary\n",
        "                row_pos.append(sentence_pos)\n",
        "                pos_counts.update(sentence_pos)\n",
        "            df_pos.append(row_pos)\n",
        "        all_pos.append(df_pos)\n",
        "        \n",
        "#         \n",
        "    return all_pos, pos_counts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpJnQpyr5FE7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pos_data = tag_pos(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIfMuuoj0-H-",
        "colab_type": "code",
        "outputId": "0dbe5acb-eaf0-4969-9faa-ab2b20d45a1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "print(list_of_sentences[0])\n",
        "print(pos_data[0][0][0])"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Rick', 'grew', 'up', 'in', 'a', 'troubled', 'household', '.']\n",
            "[['PROPN', 'VERB', 'PART', 'ADP', 'DET', 'ADJ', 'NOUN', 'PUNCT'], ['PRON', 'ADV', 'VERB', 'ADJ', 'NOUN', 'ADP', 'NOUN', 'PUNCT', 'CCONJ', 'VERB', 'ADP', 'NOUN', 'PUNCT'], ['PRON', 'VERB', 'ADV', 'ADJ', 'ADP', 'PROPN', 'VERB', 'VERB', 'ADP', 'DET', 'NOUN', 'PUNCT'], ['DET', 'NOUN', 'VERB', 'PRON', 'PART', 'VERB', 'DET', 'ADJ', 'NOUN', 'PUNCT'], ['PRON', 'VERB', 'ADJ', 'ADV', 'PUNCT'], ['PRON', 'VERB', 'DET', 'NOUN', 'PUNCT']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlD7OeVX0Z8M",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqeJfOK85FFB",
        "colab_type": "code",
        "outputId": "309d699c-82df-4c18-dd6b-aa3136e9a118",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "model = Word2Vec(list_of_sentences, size=EMBED_DIM, min_count=1)\n",
        "name = 'spacy_word2vec' + str(EMBED_DIM) + '.model'\n",
        "model.save(name)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cl-2JSezAMY7",
        "colab_type": "code",
        "outputId": "686cb621-8fa5-436b-d8e9-f419184fda0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "w2v = 'spacy_word2vec' + str(EMBED_DIM) + '.model'\n",
        "WORD2VEC = Word2Vec.load(w2v)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAiqnf9gS8W_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def new_word_tokenize(sentence):\n",
        "    return [pos.text for pos in get_pos(sentence)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pELXASv5FFP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_one_hot(group, row, sentence, word):\n",
        "#     print((group, row, sentence, word))\n",
        "    pos = pos_data[0][group][row][sentence][word]\n",
        "#     pos = pos_data[group][row][sentence][word]\n",
        "#     print(pos)\n",
        "    \n",
        "    return [1 if pos == list(pos_data[1].keys())[i] else 0 for i in range(len(pos_data[1].keys()))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9xUUjvZSZ0E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_vector(i, j, row, sentence, word, group):\n",
        "    return np.array(list(WORD2VEC.wv[word]) + get_one_hot(group, row[0], i-1, j))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mc1jQK7B5FFn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def embed(train_data, dev_data, test_data):\n",
        "    training_data = [] \n",
        "    for row in train_data.iterrows():\n",
        "        sentences = [row[1][0]]\n",
        "        for i in range(1, 7):\n",
        "#             print(row[1][i])\n",
        "            lst = [create_vector(i, j, row, row[1][i], word, 0) \\\n",
        "                   for j, word in enumerate(new_word_tokenize(row[1][i]))]\n",
        "            sentences.append(lst)\n",
        "        sentences.append(row[1][7])\n",
        "        training_data.append(sentences)\n",
        "#     return training_data, 1, 1\n",
        "    \n",
        "    development_data = []\n",
        "    for row in dev_data.iterrows():\n",
        "        sentences = [row[1][0]]\n",
        "        for i in range(1, 7):\n",
        "            lst = [create_vector(i, j, row, row[1][i], word, 1) \\\n",
        "                   for j, word in enumerate(new_word_tokenize(row[1][i]))]\n",
        "#             lst = [np.array(list(WORD2VEC.wv[word]) + get_one_hot(1, row[0], i-1, j)) \\\n",
        "#                    for j, word in enumerate(new_word_tokenize(row[1][i]))]\n",
        "            sentences.append(lst)\n",
        "        sentences.append(row[1][7])\n",
        "        development_data.append(sentences)\n",
        "        \n",
        "    testing_data = []\n",
        "    for row in test_data.iterrows():\n",
        "        sentences = [row[1][0]]\n",
        "        for i in range(1, 7):\n",
        "            lst = [create_vector(i, j, row, row[1][i], word, 2) \\\n",
        "                   for j, word in enumerate(new_word_tokenize(row[1][i]))]\n",
        "#             lst = [np.array(list(WORD2VEC.wv[word]) + get_one_hot(2, row[0], i-1, j)) \\\n",
        "#                    for j, word in enumerate(new_word_tokenize(row[1][i]))]\n",
        "            sentences.append(lst)\n",
        "        testing_data.append(sentences)\n",
        "        \n",
        "    return training_data, development_data, testing_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNe7dxQ6bxll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def new_embed(train_data, dev_data, test_data):\n",
        "    training_data = [] \n",
        "    for row in train_data.iterrows():\n",
        "        pos = [row[1][0]]\n",
        "        neg = [row[1][0]]\n",
        "        for i in range(1, 5):\n",
        "            lst = [create_vector(i, j, row, row[1][i], word, 0) \\\n",
        "                    for j, word in enumerate(new_word_tokenize(row[1][i]))]\n",
        "            pos.append(lst)\n",
        "            neg.append(lst)\n",
        "        if row[1][7] == 1:\n",
        "            pos.append([np.array(list(WORD2VEC.wv[word]) + get_one_hot(0, row[0], 4, j)) \\\n",
        "                   for j, word in enumerate(new_word_tokenize(row[1][5]))])\n",
        "            neg.append([np.array(list(WORD2VEC.wv[word]) + get_one_hot(0, row[0], 5, j)) \\\n",
        "                   for j, word in enumerate(new_word_tokenize(row[1][6]))])\n",
        "        elif row[1][7] == 2:\n",
        "            pos.append([np.array(list(WORD2VEC.wv[word]) + get_one_hot(0, row[0], 5, j)) \\\n",
        "                   for j, word in enumerate(new_word_tokenize(row[1][6]))])\n",
        "            neg.append([np.array(list(WORD2VEC.wv[word]) + get_one_hot(0, row[0], 4, j)) \\\n",
        "                   for j, word in enumerate(new_word_tokenize(row[1][5]))])\n",
        "        pos.append(1)\n",
        "        neg.append(0)\n",
        "        training_data.append(pos)\n",
        "        training_data.append(neg)\n",
        "    \n",
        "    development_data = []\n",
        "    for row in dev_data.iterrows():\n",
        "        sentences = [row[1][0]]\n",
        "        for i in range(1, 7):\n",
        "            lst = [create_vector(i, j, row, row[1][i], word, 1) \\\n",
        "                    for j, word in enumerate(new_word_tokenize(row[1][i]))]\n",
        "            sentences.append(lst)\n",
        "        sentences.append(row[1][7] - 1)\n",
        "        development_data.append(sentences)\n",
        "        \n",
        "    testing_data = []\n",
        "    for row in test_data.iterrows():\n",
        "        sentences = [row[1][0]]\n",
        "        for i in range(1, 7):\n",
        "            lst = [create_vector(i, j, row, row[1][i], word, 2) \\\n",
        "                    for j, word in enumerate(new_word_tokenize(row[1][i]))]\n",
        "            sentences.append(lst)\n",
        "        testing_data.append(sentences)\n",
        "        \n",
        "    return training_data, development_data, testing_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4l_vtXfJ5FFr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_data, development_data, testing_data = new_embed(data[0], data[1], data[2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfipjZIY5FGA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NSP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NSP, self).__init__()\n",
        "        self.beginning = nn.GRU(EMBED_DIM+17, HIDDEN_DIM, LAYERS, batch_first=True, bidirectional=False)\n",
        "        self.ending = nn.GRU(EMBED_DIM+17, HIDDEN_DIM, LAYERS, batch_first=True, bidirectional=False)\n",
        "        self.linear = nn.Linear(HIDDEN_DIM, 2)\n",
        "        self.softmax = nn.LogSoftmax(dim=0)\n",
        "        self.criterion = nn.NLLLoss()\n",
        "        self.optimizer = optim.Adam(self.parameters(), lr=LR)\n",
        "        self.cuda(device=DEVICE)\n",
        "        \n",
        "    def setup(self, data):\n",
        "        input_1 = torch.tensor(np.expand_dims(data[0] + data[1] + data[2] + data[3], axis=0), device=DEVICE, dtype=torch.float)\n",
        "        input_2 = torch.tensor(np.expand_dims(data[4], axis=0), device=DEVICE, dtype=torch.float)\n",
        "        return input_1, input_2\n",
        "\n",
        "    def compute_Loss(self, predicted_vector, gold_label):\n",
        "        return self.criterion(predicted_vector, gold_label)\n",
        "\n",
        "    def forward(self, data):\n",
        "        input_1, input_2 = self.setup(data)\n",
        "        h_0 = torch.zeros((LAYERS, 1, HIDDEN_DIM), device=DEVICE)\n",
        "        __, h_n = self.beginning(input_1, h_0)\n",
        "        output, __ = self.ending(input_2, h_n)\n",
        "        x = output[0][-1]\n",
        "        x = self.linear(x)\n",
        "        x = self.softmax(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ST4QTBMq5FGG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "54d70e57-ea03-4f8a-d13b-55a29da7101a"
      },
      "source": [
        "print('Initializing Model')\n",
        "model = NSP()\n",
        "prev_dev_acc = 0.0\n",
        "for epoch in range(EPOCHS):\n",
        "    checkpoint = PATH + '-e' + str((epoch + 1))\n",
        "    model.train()\n",
        "    model.optimizer.zero_grad()\n",
        "    loss = None\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    start_time = time.time()\n",
        "    print('Training started for epoch {}'.format(epoch + 1))\n",
        "    random.shuffle(training_data)\n",
        "    N = len(training_data)\n",
        "    for index  in tqdm(range(N)):\n",
        "        model.optimizer.zero_grad()\n",
        "        sample = training_data[index]\n",
        "        input_vector = sample[1:6]\n",
        "        gold_label = sample[6]\n",
        "        predicted_vector = model(input_vector)\n",
        "        predicted_label = torch.argmax(predicted_vector)\n",
        "        correct += int(predicted_label == gold_label)\n",
        "        total += 1\n",
        "        loss = model.compute_Loss(predicted_vector.view(1, -1), torch.tensor([gold_label], device=DEVICE))\n",
        "        loss.backward()\n",
        "        model.optimizer.step()\n",
        "    print('Training accuracy for epoch {}: {}'.format(epoch + 1, correct / total))\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    start_time = time.time()\n",
        "    random.shuffle(development_data)\n",
        "    N = len(development_data)\n",
        "    model.eval()\n",
        "    model.optimizer.zero_grad()\n",
        "    for index in tqdm(range(N)):\n",
        "        sample = development_data[index]\n",
        "        input_1 = sample[1:6]\n",
        "        input_2 = sample[1:5] + [sample[6]]\n",
        "        gold_label = sample[7]\n",
        "        prediction_1 = model(input_1)\n",
        "        prediction_2 = model(input_2)\n",
        "        prob_truthful_1 = prediction_1[1]\n",
        "        prob_false_1 = prediction_1[0]\n",
        "        prob_truthful_2 = prediction_2[1]\n",
        "        prob_false_2 = prediction_2[0]\n",
        "        probs = [prob_truthful_1, prob_false_1, prob_truthful_2, prob_false_2]\n",
        "        max_index = probs.index(max(probs))\n",
        "        if max_index == 0 or max_index == 3:\n",
        "            predicted_label = 0\n",
        "        if max_index == 1 or max_index == 2:\n",
        "            predicted_label = 1\n",
        "        correct += int(predicted_label == gold_label)\n",
        "        total += 1\n",
        "    dev_acc = correct / total\n",
        "    if dev_acc > prev_dev_acc and dev_acc > 0.67:\n",
        "        prev_dev_acc = dev_acc\n",
        "        print('New Best Accuracy: {}'.format(dev_acc))\n",
        "        acc = int(100 * dev_acc)\n",
        "        torch.save(model.state_dict(), checkpoint + '-a' + str(acc) + '.pt')\n",
        "    print('Development accuracy for epoch {}: {}'.format(epoch + 1, correct / total))\n",
        "\n",
        "torch.save(model.state_dict(), PATH + '-final.pt')"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 3/2994 [00:00<01:41, 29.52it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Initializing Model\n",
            "Training started for epoch 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2994/2994 [00:14<00:00, 210.18it/s]\n",
            "  9%|▊         | 32/374 [00:00<00:01, 311.60it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training accuracy for epoch 1: 0.5156980627922512\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 374/374 [00:01<00:00, 334.40it/s]\n",
            "  1%|          | 21/2994 [00:00<00:14, 205.23it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Development accuracy for epoch 1: 0.6149732620320856\n",
            "Training started for epoch 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2994/2994 [00:14<00:00, 206.85it/s]\n",
            "  9%|▉         | 34/374 [00:00<00:01, 331.32it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training accuracy for epoch 2: 0.5297261189044756\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 374/374 [00:01<00:00, 337.54it/s]\n",
            "  1%|          | 22/2994 [00:00<00:13, 212.56it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Development accuracy for epoch 2: 0.6310160427807486\n",
            "Training started for epoch 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2994/2994 [00:14<00:00, 211.64it/s]\n",
            "  9%|▉         | 34/374 [00:00<00:01, 338.11it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training accuracy for epoch 3: 0.5534402137608551\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 374/374 [00:01<00:00, 340.98it/s]\n",
            "  1%|          | 21/2994 [00:00<00:14, 209.17it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Development accuracy for epoch 3: 0.6390374331550802\n",
            "Training started for epoch 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2994/2994 [00:14<00:00, 207.03it/s]\n",
            "  9%|▉         | 35/374 [00:00<00:00, 346.96it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training accuracy for epoch 4: 0.5647962591850367\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 374/374 [00:01<00:00, 339.78it/s]\n",
            "  1%|          | 22/2994 [00:00<00:14, 212.25it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Development accuracy for epoch 4: 0.6256684491978609\n",
            "Training started for epoch 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2994/2994 [00:14<00:00, 211.59it/s]\n",
            "  9%|▉         | 35/374 [00:00<00:00, 346.21it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training accuracy for epoch 5: 0.5801603206412825\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 374/374 [00:01<00:00, 341.66it/s]\n",
            "  1%|          | 22/2994 [00:00<00:14, 211.72it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Development accuracy for epoch 5: 0.6256684491978609\n",
            "Training started for epoch 6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2994/2994 [00:14<00:00, 210.89it/s]\n",
            "  9%|▉         | 35/374 [00:00<00:00, 341.97it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training accuracy for epoch 6: 0.5878423513694054\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 374/374 [00:01<00:00, 333.89it/s]\n",
            "  1%|          | 22/2994 [00:00<00:13, 215.17it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Development accuracy for epoch 6: 0.6203208556149733\n",
            "Training started for epoch 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2994/2994 [00:14<00:00, 213.39it/s]\n",
            "  9%|▊         | 32/374 [00:00<00:01, 317.29it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training accuracy for epoch 7: 0.5881763527054108\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 374/374 [00:01<00:00, 339.97it/s]\n",
            "  1%|          | 22/2994 [00:00<00:13, 216.87it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Development accuracy for epoch 7: 0.6336898395721925\n",
            "Training started for epoch 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2994/2994 [00:14<00:00, 213.18it/s]\n",
            "  9%|▉         | 34/374 [00:00<00:01, 331.95it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training accuracy for epoch 8: 0.5968603874415498\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 374/374 [00:01<00:00, 341.20it/s]\n",
            "  1%|          | 22/2994 [00:00<00:13, 216.32it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Development accuracy for epoch 8: 0.6363636363636364\n",
            "Training started for epoch 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2994/2994 [00:13<00:00, 214.19it/s]\n",
            "  9%|▉         | 35/374 [00:00<00:00, 343.38it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training accuracy for epoch 9: 0.5988643954575819\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 374/374 [00:01<00:00, 338.37it/s]\n",
            "  1%|          | 21/2994 [00:00<00:14, 205.75it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Development accuracy for epoch 9: 0.6470588235294118\n",
            "Training started for epoch 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2994/2994 [00:13<00:00, 213.92it/s]\n",
            " 10%|▉         | 36/374 [00:00<00:00, 353.70it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training accuracy for epoch 10: 0.6045424181696727\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 374/374 [00:01<00:00, 342.29it/s]\n",
            "  1%|          | 22/2994 [00:00<00:13, 218.32it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Development accuracy for epoch 10: 0.6577540106951871\n",
            "Training started for epoch 11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2994/2994 [00:13<00:00, 216.77it/s]\n",
            "  9%|▉         | 34/374 [00:00<00:01, 333.82it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training accuracy for epoch 11: 0.6052104208416834\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 374/374 [00:01<00:00, 345.50it/s]\n",
            "  1%|          | 21/2994 [00:00<00:14, 207.48it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Development accuracy for epoch 11: 0.660427807486631\n",
            "Training started for epoch 12\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2994/2994 [00:13<00:00, 215.93it/s]\n",
            " 10%|▉         | 36/374 [00:00<00:00, 350.09it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training accuracy for epoch 12: 0.614562458249833\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 374/374 [00:01<00:00, 344.40it/s]\n",
            "  1%|          | 22/2994 [00:00<00:13, 217.84it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Development accuracy for epoch 12: 0.660427807486631\n",
            "Training started for epoch 13\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2994/2994 [00:13<00:00, 216.45it/s]\n",
            " 10%|▉         | 36/374 [00:00<00:00, 359.75it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training accuracy for epoch 13: 0.6169004676018705\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 374/374 [00:01<00:00, 350.33it/s]\n",
            "  1%|          | 21/2994 [00:00<00:14, 205.91it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Development accuracy for epoch 13: 0.6684491978609626\n",
            "Training started for epoch 14\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2994/2994 [00:13<00:00, 215.81it/s]\n",
            " 10%|▉         | 36/374 [00:00<00:00, 357.55it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training accuracy for epoch 14: 0.614562458249833\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 374/374 [00:01<00:00, 342.00it/s]\n",
            "  1%|          | 20/2994 [00:00<00:15, 194.77it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Development accuracy for epoch 14: 0.6657754010695187\n",
            "Training started for epoch 15\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2994/2994 [00:14<00:00, 211.62it/s]\n",
            "  9%|▉         | 35/374 [00:00<00:00, 340.78it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training accuracy for epoch 15: 0.6212424849699398\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 374/374 [00:01<00:00, 339.17it/s]\n",
            "  1%|          | 23/2994 [00:00<00:13, 226.05it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Development accuracy for epoch 15: 0.6657754010695187\n",
            "Training started for epoch 16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2994/2994 [00:14<00:00, 207.42it/s]\n",
            "  9%|▉         | 33/374 [00:00<00:01, 329.32it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training accuracy for epoch 16: 0.6235804943219773\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 374/374 [00:01<00:00, 340.12it/s]\n",
            "  1%|          | 22/2994 [00:00<00:13, 212.83it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "New Best Accuracy: 0.6818181818181818\n",
            "Development accuracy for epoch 16: 0.6818181818181818\n",
            "Training started for epoch 17\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2994/2994 [00:13<00:00, 216.01it/s]\n",
            "  9%|▉         | 35/374 [00:00<00:00, 348.87it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training accuracy for epoch 17: 0.6269205076820308\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 374/374 [00:01<00:00, 331.13it/s]\n",
            "  1%|          | 21/2994 [00:00<00:14, 203.78it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Development accuracy for epoch 17: 0.6764705882352942\n",
            "Training started for epoch 18\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2994/2994 [00:13<00:00, 217.78it/s]\n",
            " 10%|▉         | 36/374 [00:00<00:00, 354.29it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training accuracy for epoch 18: 0.6255845023380093\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 374/374 [00:01<00:00, 349.94it/s]\n",
            "  1%|          | 23/2994 [00:00<00:13, 222.67it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Development accuracy for epoch 18: 0.6711229946524064\n",
            "Training started for epoch 19\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2994/2994 [00:13<00:00, 216.84it/s]\n",
            "  9%|▉         | 35/374 [00:00<00:00, 342.79it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training accuracy for epoch 19: 0.6315965263861055\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 374/374 [00:01<00:00, 347.48it/s]\n",
            "  1%|          | 23/2994 [00:00<00:13, 221.26it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Development accuracy for epoch 19: 0.6684491978609626\n",
            "Training started for epoch 20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2994/2994 [00:13<00:00, 216.45it/s]\n",
            " 10%|▉         | 36/374 [00:00<00:00, 350.42it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training accuracy for epoch 20: 0.6429525718102872\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 374/374 [00:01<00:00, 345.70it/s]\n",
            "  1%|          | 22/2994 [00:00<00:13, 214.05it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Development accuracy for epoch 20: 0.6684491978609626\n",
            "Training started for epoch 21\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2994/2994 [00:13<00:00, 218.79it/s]\n",
            " 10%|▉         | 37/374 [00:00<00:00, 369.67it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training accuracy for epoch 21: 0.6419505678022712\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 374/374 [00:01<00:00, 340.17it/s]\n",
            "  1%|          | 21/2994 [00:00<00:14, 203.40it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Development accuracy for epoch 21: 0.6657754010695187\n",
            "Training started for epoch 22\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2994/2994 [00:13<00:00, 217.31it/s]\n",
            " 10%|▉         | 36/374 [00:00<00:00, 355.37it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training accuracy for epoch 22: 0.6409485637942551\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 374/374 [00:01<00:00, 351.23it/s]\n",
            "  1%|          | 23/2994 [00:00<00:13, 221.72it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Development accuracy for epoch 22: 0.6737967914438503\n",
            "Training started for epoch 23\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2994/2994 [00:13<00:00, 218.55it/s]\n",
            "  9%|▉         | 35/374 [00:00<00:00, 347.71it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training accuracy for epoch 23: 0.6429525718102872\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 374/374 [00:01<00:00, 351.60it/s]\n",
            "  1%|          | 23/2994 [00:00<00:13, 225.37it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Development accuracy for epoch 23: 0.6737967914438503\n",
            "Training started for epoch 24\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2994/2994 [00:14<00:00, 212.55it/s]\n",
            "  9%|▉         | 35/374 [00:00<00:00, 348.32it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training accuracy for epoch 24: 0.6499665998663995\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 374/374 [00:01<00:00, 350.47it/s]\n",
            "  1%|          | 21/2994 [00:00<00:14, 206.82it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Development accuracy for epoch 24: 0.6631016042780749\n",
            "Training started for epoch 25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2994/2994 [00:13<00:00, 216.33it/s]\n",
            " 10%|▉         | 37/374 [00:00<00:00, 362.00it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training accuracy for epoch 25: 0.654308617234469\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 374/374 [00:01<00:00, 345.74it/s]\n",
            "  1%|          | 21/2994 [00:00<00:14, 205.27it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Development accuracy for epoch 25: 0.6577540106951871\n",
            "Training started for epoch 26\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2994/2994 [00:13<00:00, 215.65it/s]\n",
            " 10%|▉         | 37/374 [00:00<00:00, 363.69it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training accuracy for epoch 26: 0.6492985971943888\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 374/374 [00:01<00:00, 351.64it/s]\n",
            "  1%|          | 23/2994 [00:00<00:13, 226.86it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Development accuracy for epoch 26: 0.6550802139037433\n",
            "Training started for epoch 27\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 70%|██████▉   | 2090/2994 [00:09<00:04, 219.56it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-c3298f2b00d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_Loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_vector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgold_label\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training accuracy for epoch {}: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}