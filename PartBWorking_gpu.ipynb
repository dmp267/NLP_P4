{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1894,
     "status": "ok",
     "timestamp": 1575870143143,
     "user": {
      "displayName": "Daniel Parangi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBgRNESsNAk7E6CovKP6H8l5JpOEnJ7tIh6JqsL=s64",
      "userId": "01211561534677666164"
     },
     "user_tz": 300
    },
    "id": "EytCBDLKhwaw",
    "outputId": "830e7aad-fb6c-4f16-ec04-103027299d03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
      "/gdrive/My Drive/College/F19/CS 4740/NLP_P4\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/gdrive')\n",
    "# %cd /gdrive/My Drive/College/F19/CS 4740/NLP_P4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M6r1uobfw3t7"
   },
   "outputs": [],
   "source": [
    "# %pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 114
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7608,
     "status": "ok",
     "timestamp": 1575870148980,
     "user": {
      "displayName": "Daniel Parangi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBgRNESsNAk7E6CovKP6H8l5JpOEnJ7tIh6JqsL=s64",
      "userId": "01211561534677666164"
     },
     "user_tz": 300
    },
    "id": "tlGDHGSbh-DS",
    "outputId": "8331e37e-1df6-4b54-d00a-72af1fe32ccf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/danielparangi/.cache/torch/hub/huggingface_transformers_master\n",
      "Using cache found in /Users/danielparangi/.cache/torch/hub/huggingface_transformers_master\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "train_data = pd.read_csv('./gpu_train.csv', encoding='latin-1')\n",
    "dev_data = pd.read_csv('./gpu_dev.csv', encoding='latin-1')\n",
    "test_data = pd.read_csv('./gpu_test.csv', encoding='latin-1')\n",
    "data = [train_data, dev_data, test_data]\n",
    "bert = torch.hub.load('huggingface/transformers', 'model', 'bert-base-uncased')\n",
    "tokenizer = torch.hub.load('huggingface/transformers', 'tokenizer', 'bert-base-uncased')\n",
    "\n",
    "EPOCHS = 1\n",
    "LR = 0.001\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "NAME = 'bert1'\n",
    "CURRENT = os.curdir\n",
    "MODELS = os.path.join(CURRENT, 'experimental_models')\n",
    "PATH = os.path.join(MODELS, NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dxRuwLmHiILC"
   },
   "outputs": [],
   "source": [
    "def train_and_classify(training_data, development_data, testing_data, STOP):\n",
    "    class BertnaryClassification(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(BertnaryClassification, self).__init__()\n",
    "            self.linear = nn.Linear(768, 2)\n",
    "            self.softmax = nn.LogSoftmax(dim=0)\n",
    "            self.criterion = nn.NLLLoss()\n",
    "            self.optimizer = optim.Adam(self.parameters(), lr=LR)\n",
    "#             self.cuda(device=DEVICE)\n",
    "\n",
    "        def compute_Loss(self, predicted_vector, gold_label):\n",
    "            return self.criterion(predicted_vector, gold_label)\n",
    "\n",
    "        def forward(self, input_vector):\n",
    "            features = torch.mean(bert(input_vector)[0].squeeze(), dim=0).to(DEVICE)\n",
    "            prediction = self.linear(features)\n",
    "            return self.softmax(prediction)\n",
    "\n",
    "    def setup(training_data, development_data, testing_data):\n",
    "        print('Initializing Setup...')\n",
    "        train_data = []\n",
    "        for row in training_data.iterrows():\n",
    "            ID = row[1][0]\n",
    "            if row[1][7] == 1:\n",
    "                pos_story = ' '.join(word for word in row[1][1:6].values)\n",
    "                pos_story = torch.tensor([tokenizer.encode(pos_story, add_special_tokens=True)])\n",
    "                pos = (ID, pos_story, 1)\n",
    "                neg_story = ' '.join(word for word in list(row[1][1:5].values) + [row[1][6]])\n",
    "                neg_story = torch.tensor([tokenizer.encode(neg_story, add_special_tokens=True)])\n",
    "                neg = (ID, neg_story, 0)\n",
    "            else:\n",
    "                neg_story = ' '.join(word for word in row[1][1:6].values)\n",
    "                neg_story = torch.tensor([tokenizer.encode(neg_story, add_special_tokens=True)])\n",
    "                neg = (ID, neg_story, 0)\n",
    "                pos_story = ' '.join(word for word in list(row[1][1:5].values) + [row[1][6]])\n",
    "                pos_story = torch.tensor([tokenizer.encode(pos_story, add_special_tokens=True)])\n",
    "                pos = (ID, pos_story, 1)\n",
    "            train_data.append(pos)\n",
    "            train_data.append(neg)\n",
    "\n",
    "        dev_data = []\n",
    "        for row in development_data.iterrows():\n",
    "            ID = row[1][0]\n",
    "            LABEL = row[1][7] - 1\n",
    "            story_1 = ' '.join(word for word in row[1][1:6].values)\n",
    "            story_1 = torch.tensor([tokenizer.encode(story_1, add_special_tokens=True)])\n",
    "            story_2 = ' '.join(word for word in list(row[1][1:5].values) + [row[1][6]])\n",
    "            story_2 = torch.tensor([tokenizer.encode(story_2, add_special_tokens=True)])\n",
    "            sample = (ID, story_1, story_2, LABEL)\n",
    "            dev_data.append(sample)\n",
    "\n",
    "        test_data = []\n",
    "        for row in testing_data.iterrows():\n",
    "            ID = row[1][0]\n",
    "            story_1 = ' '.join(word for word in row[1][1:6].values)\n",
    "            story_1 = torch.tensor([tokenizer.encode(story_1, add_special_tokens=True)])\n",
    "            story_2 = ' '.join(word for word in list(row[1][1:5].values) + [row[1][6]])\n",
    "            story_2 = torch.tensor([tokenizer.encode(story_2, add_special_tokens=True)])\n",
    "            sample = (ID, story_1, story_2)\n",
    "            test_data.append(sample)\n",
    "\n",
    "        return train_data, dev_data, test_data\n",
    "\n",
    "    def train(train_data):\n",
    "        model = BertnaryClassification()\n",
    "        for epoch in range(EPOCHS):\n",
    "            model.train()\n",
    "            model.optimizer.zero_grad()\n",
    "            loss = None\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            random.shuffle(train_data)\n",
    "            N = len(train_data)\n",
    "            print('\\nTraining...')\n",
    "            for index in tqdm(range(N)):\n",
    "                if index == STOP:\n",
    "                    break\n",
    "                model.optimizer.zero_grad()\n",
    "                __, input_vector, gold_label = train_data[index]\n",
    "                predicted_vector = model(input_vector)\n",
    "                predicted_label = torch.argmax(predicted_vector)\n",
    "                loss = model.compute_Loss(predicted_vector.view(1, -1), torch.tensor([gold_label], device=DEVICE))\n",
    "                loss.backward()\n",
    "                model.optimizer.step()\n",
    "        return model\n",
    "\n",
    "    def validate(dev_data, model):\n",
    "        model.eval()\n",
    "        model.optimizer.zero_grad()\n",
    "        N = len(dev_data)\n",
    "        predictions = []\n",
    "        print('\\nValidating...')\n",
    "        for index in tqdm(range(N)):\n",
    "            __, input_1, input_2, __ = dev_data[index]\n",
    "            prediction_1 = model(input_1)\n",
    "            prediction_2 = model(input_2)\n",
    "            prob_truthful_1 = prediction_1[1]\n",
    "            prob_false_1 = prediction_1[0]\n",
    "            prob_truthful_2 = prediction_2[1]\n",
    "            prob_false_2 = prediction_2[0]\n",
    "            probs = [prob_truthful_1, prob_false_1, prob_truthful_2, prob_false_2]\n",
    "            max_index = probs.index(max(probs))\n",
    "            if max_index == 0 or max_index == 3:\n",
    "                predicted_label = 0\n",
    "            if max_index == 1 or max_index == 2:\n",
    "                predicted_label = 1\n",
    "            predictions.append(predicted_label + 1)\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for i in range(len(predictions)):\n",
    "            correct += int(predictions[i] == dev_data[i][3])\n",
    "            total += 1\n",
    "        return correct / total\n",
    "\n",
    "    def classify(test_data, model):\n",
    "        model.eval()\n",
    "        model.optimizer.zero_grad()\n",
    "        N = len(test_data)\n",
    "        ids = []\n",
    "        predictions = []\n",
    "        print('\\nClassifying...')\n",
    "        for index in tqdm(range(N)):\n",
    "            ID, input_1, input_2 = test_data[index]\n",
    "            prediction_1 = model(input_1)\n",
    "            prediction_2 = model(input_2)\n",
    "            prob_truthful_1 = prediction_1[1]\n",
    "            prob_false_1 = prediction_1[0]\n",
    "            prob_truthful_2 = prediction_2[1]\n",
    "            prob_false_2 = prediction_2[0]\n",
    "            probs = [prob_truthful_1, prob_false_1, prob_truthful_2, prob_false_2]\n",
    "            max_index = probs.index(max(probs))\n",
    "            if max_index == 0 or max_index == 3:\n",
    "                predicted_label = 0\n",
    "            if max_index == 1 or max_index == 2:\n",
    "                predicted_label = 1\n",
    "            ids.append(ID)\n",
    "            predictions.append(predicted_label + 1)\n",
    "        df = pd.DataFrame({'Id': ids, 'Prediction': predictions}, columns = ['Id', 'Prediction'])\n",
    "        df.to_csv(NAME, index=False)\n",
    "        return predictions\n",
    "\n",
    "    train_data, dev_data, test_data = setup(training_data, development_data, testing_data)\n",
    "\n",
    "    # create and train model\n",
    "    model = train(train_data)\n",
    "\n",
    "    # evaulate model\n",
    "    acc = validate(dev_data, model)\n",
    "    acc = round(acc * 100, 2)\n",
    "    print('Validation Accurary: ' + str(acc) + '%')\n",
    "    # return classify(test_data, model)\n",
    "    if acc > 0.60:\n",
    "        return (model, STOP, acc)\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "JD0nIrxPjAvd",
    "outputId": "840259f2-2c64-450c-eee5-11da78e34969"
   },
   "outputs": [],
   "source": [
    "models = []\n",
    "for i in range(6):\n",
    "    print('STOP is {}'.format((2**i)*100))\n",
    "    models.append(train_and_classify(train_data, dev_data, test_data, (2**i)*100))\n",
    "models = list(filter(lambda elt: elt != False, models))\n",
    "for i, x in enumerate(models):\n",
    "    model = x[0]\n",
    "    stop = x[1]\n",
    "    acc = x[2]\n",
    "    torch.save(model.state_dict(), PATH + '-stop'+ str(stop) + '-acc' + str(acc) + '.pt')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1s5W4eNLECx4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "PartBWorking_gpu.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
